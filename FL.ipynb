{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aef55a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICES = \"GPUS\" # Moguce vrijednosti: \"CPU\", \"GPU:0\", \"GPU:1\", \"GPUS\"\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "import logging\n",
    "# os.environ['TF_CUDNN_DETERMINISTIC']='1'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "# \n",
    "logging.getLogger('tensorflow').setLevel(logging.FATAL)\n",
    "\n",
    "# if DEVICES == 'CPU':\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "# elif DEVICES == 'GPU:0':\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "# elif DEVICES == 'GPU:1':\n",
    "    # os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from dataset.dataset_loader import NerProcessor, FewNERDProcessor, create_tf_dataset_for_client, split_to_tf_datasets, batch_features\n",
    "from utils.fl_utils import *\n",
    "from models.model import build_BertNer, MaskedSparseCategoricalCrossentropy\n",
    "from tokenization import FullTokenizer\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import tensorflow_federated as tff\n",
    "\n",
    "\n",
    "import bert_modeling\n",
    "\n",
    "\n",
    "if DEVICES == 'CPU':\n",
    "    cl_tf_devices = tf.config.list_logical_devices('CPU')\n",
    "elif DEVICES == 'GPUS':\n",
    "    cl_tf_devices = tf.config.list_logical_devices('GPU')\n",
    "# else:\n",
    "    # cl_tf_devices = tf.config.list_logical_devices('GPU')[:1]\n",
    "# tff.backends.native.set_local_execution_context(\n",
    "#     server_tf_device=tf.config.list_logical_devices('CPU')[0],\n",
    "#     client_tf_devices=cl_tf_devices)\n",
    "\n",
    "\n",
    "# Pretrained models\n",
    "TINY = 'uncased_L-2_H-128_A-2'\n",
    "MODEL_2_256 = 'uncased_L-2_H-256_A-4'\n",
    "MODEL_2_512 = 'uncased_L-2_H-512_A-8'\n",
    "MODEL_2_768 = 'uncased_L-2_H-768_A-12'\n",
    "\n",
    "MODEL_4_128 = 'uncased_L-4_H-128_A-2'\n",
    "MINI = 'uncased_L-4_H-256_A-4'\n",
    "SMALL = 'uncased_L-4_H-512_A-8'\n",
    "MODEL_4_768 = 'uncased_L-4_H-768_A-12'\n",
    "\n",
    "MODEL_6_128 = 'uncased_L-6_H-128_A-2'\n",
    "MODEL_6_256 = 'uncased_L-6_H-256_A-4'\n",
    "MODEL_6_512 = 'uncased_L-6_H-512_A-8'\n",
    "MODEL_6_768 = 'uncased_L-6_H-768_A-12'\n",
    "\n",
    "MODEL_8_128 = 'uncased_L-8_H-128_A-2'\n",
    "MODEL_8_256 = 'uncased_L-8_H-256_A-4'\n",
    "MEDIUM = 'uncased_L-8_H-512_A-8'\n",
    "MODEL_8_768 = 'uncased_L-8_H-768_A-12'\n",
    "\n",
    "MODEL_10_128 = 'uncased_L-10_H-128_A-2'\n",
    "MODEL_10_256 = 'uncased_L-10_H-256_A-4'\n",
    "MODEL_10_512 = 'uncased_L-10_H-512_A-8'\n",
    "MODEL_10_768 = 'uncased_L-10_H-768_A-12'\n",
    "\n",
    "MODEL_12_128='uncased_L-12_H-128_A-2'\n",
    "MODEL_12_256 = 'uncased_L-12_H-256_A-4'\n",
    "MODEL_12_512 = 'uncased_L-12_H-512_A-8'\n",
    "BASE = 'uncased_L-12_H-768_A-12'\n",
    "\n",
    "\n",
    "MODEL = os.path.join(\"models\", MODEL_8_256)\n",
    "SEQ_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "PRETRAINED = True\n",
    "\n",
    "\n",
    "# processor = NerProcessor('dataset/conll')\n",
    "processor = FewNERDProcessor('dataset/few_nerd')\n",
    "datas = processor.data_dir.split('/')[-1]\n",
    "tokenizer = FullTokenizer(os.path.join(MODEL, \"vocab.txt\"), True)\n",
    "train_features = processor.get_train_as_features(SEQ_LEN, tokenizer)\n",
    "eval_features = processor.get_test_as_features(SEQ_LEN, tokenizer)\n",
    "\n",
    "# Name of file\n",
    "modelSize=\"\"\n",
    "pretr=\"\"\n",
    "\n",
    "modelSize = {\n",
    "  'models/uncased_L-2_H-128_A-2': lambda: \"tiny_2_128\",\n",
    "  'models/uncased_L-2_H-256_A-4': lambda: \"model_2_256\",\n",
    "  'models/uncased_L-2_H-512_A-8': lambda: \"model_2_512\",\n",
    "  'models/uncased_L-2_H-768_A-12': lambda: \"model_2_768\",\n",
    "  'models/uncased_L-4_H-128_A-2': lambda: \"model_4_128\",\n",
    "  'models/uncased_L-4_H-256_A-4': lambda: \"mini_4_256\",\n",
    "  'models/uncased_L-4_H-512_A-8': lambda: \"small_4_512\",\n",
    "  'models/uncased_L-4_H-768_A-12': lambda: \"model_4_768\",\n",
    "  'models/uncased_L-6_H-128_A-2': lambda: \"model_6_128\",\n",
    "  'models/uncased_L-6_H-256_A-4': lambda: \"model_6_256\",\n",
    "  'models/uncased_L-6_H-512_A-8': lambda: \"model_6_512\",\n",
    "  'models/uncased_L-6_H-768_A-12': lambda: \"model_6_768\",\n",
    "  'models/uncased_L-8_H-128_A-2': lambda: \"model_8_128\",\n",
    "  'models/uncased_L-8_H-256_A-4': lambda: \"model_8_256\",\n",
    "  'models/uncased_L-8_H-512_A-8': lambda: \"medium_8_512\",\n",
    "  'models/uncased_L-8_H-768_A-12': lambda: \"model_8_768\",\n",
    "  'models/uncased_L-10_H-128_A-2': lambda: \"model_10_128\",\n",
    "  'models/uncased_L-10_H-256_A-4': lambda: \"model_10_256\",\n",
    "  'models/uncased_L-10_H-512_A-8': lambda: \"model_10_512\",\n",
    "  'models/uncased_L-10_H-768_A-12': lambda: \"model_10_768\",\n",
    "  'models/uncased_L-12_H-128_A-2': lambda: \"model_12_128\",\n",
    "  'models/uncased_L-12_H-256_A-4': lambda: \"model_12_256\",\n",
    "  'models/uncased_L-12_H-512_A-8': lambda: \"model_12_512\",\n",
    "  'models/uncased_L-12_H-768_A-12': lambda: \"base_12_768\"\n",
    "}[MODEL]()\n",
    "\n",
    "if PRETRAINED == True:\n",
    "    pretr=\"pretrained\"\n",
    "elif PRETRAINED == False:\n",
    "    pretr=\"nontrained\"\n",
    "\n",
    "\n",
    "# Wrap a Keras model for use with TFF.\n",
    "def model_fn(m_name, num_labels, seq_len, input_spec):\n",
    "    model = build_BertNer(m_name, num_labels, seq_len)\n",
    "    for layer in model.layers:\n",
    "        if (isinstance(layer, bert_modeling.BertModel)):\n",
    "            layer.trainable = False\n",
    "    return tff.learning.from_keras_model(\n",
    "        model,\n",
    "        input_spec=input_spec,\n",
    "        loss=MaskedSparseCategoricalCrossentropy()) # reduction=tf.keras.losses.Reduction.NONE))\n",
    "\n",
    "def eval_model(model, eval_data, do_print=True):\n",
    "    return evaluate(model, eval_data, \n",
    "                    processor.get_label_map(), \n",
    "                    processor.token_ind('O'), \n",
    "                    processor.token_ind('[SEP]'),\n",
    "                    processor.token_ind('[PAD]'), \n",
    "                    do_print=do_print)\n",
    "    \n",
    "# eval_features = eval_features[:5_000] # Samo prvih par tisuca za testiranje, maknuti za konaƒçne ekperimente\n",
    "eval_data_batched = batch_features(eval_features, processor.get_labels(), SEQ_LEN, tokenizer, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9682337b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_pretrained_model(model_instance, current_state):\n",
    "    model_instance = restore_model_ckpt(model_instance, MODEL)\n",
    "    model_instance.layers[-1].set_weights(state.model.trainable)\n",
    "    return model_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636993e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 Loss: 0.7825709 Examples: 13120\n",
      "Round 2 Loss: 0.6988315 Examples: 13120\n",
      "Round 3 Loss: 0.6347588 Examples: 13120\n",
      "Round 4 Loss: 0.5806408 Examples: 13120\n",
      "Round 5 Loss: 0.53062516 Examples: 13120\n",
      "Round 6 Loss: 0.50370437 Examples: 13120\n",
      "Round 7 Loss: 0.47463337 Examples: 13120\n",
      "Round 8 Loss: 0.44907138 Examples: 13120\n",
      "Round 9 Loss: 0.4381341 Examples: 13120\n",
      "Round 10 Loss: 0.42642915 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.1377    0.0571    0.0807      4064\n",
      "         BUI     0.0326    0.0074    0.0120      5007\n",
      "         EVE     0.1003    0.0244    0.0392      4104\n",
      "         LOC     0.4878    0.3590    0.4136     27227\n",
      "        MISC     0.3819    0.1524    0.2179      9558\n",
      "         ORG     0.2155    0.2250    0.2202     19077\n",
      "         PER     0.5525    0.5867    0.5691     21527\n",
      "         PRO     0.2667    0.1178    0.1634      6230\n",
      "\n",
      "   micro avg     0.3997    0.3023    0.3442     96794\n",
      "   macro avg     0.2719    0.1912    0.2145     96794\n",
      "weighted avg     0.3692    0.3023    0.3240     96794\n",
      "\n",
      "Round 11 Loss: 0.41570792 Examples: 13120\n",
      "Round 12 Loss: 0.4065878 Examples: 13120\n",
      "Round 13 Loss: 0.4007796 Examples: 13120\n",
      "Round 14 Loss: 0.39098883 Examples: 13120\n",
      "Round 15 Loss: 0.38885826 Examples: 13120\n",
      "Round 16 Loss: 0.3858668 Examples: 13120\n",
      "Round 17 Loss: 0.38012147 Examples: 13120\n",
      "Round 18 Loss: 0.37820002 Examples: 13120\n",
      "Round 19 Loss: 0.37217012 Examples: 13120\n",
      "Round 20 Loss: 0.37235457 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.2301    0.2928    0.2577      4064\n",
      "         BUI     0.1112    0.1348    0.1219      5007\n",
      "         EVE     0.1729    0.1572    0.1647      4104\n",
      "         LOC     0.5521    0.5490    0.5505     27227\n",
      "        MISC     0.3192    0.2541    0.2830      9558\n",
      "         ORG     0.2826    0.3678    0.3196     19077\n",
      "         PER     0.6551    0.7896    0.7161     21527\n",
      "         PRO     0.2894    0.2966    0.2930      6230\n",
      "\n",
      "   micro avg     0.4283    0.4727    0.4494     96794\n",
      "   macro avg     0.3266    0.3553    0.3383     96794\n",
      "weighted avg     0.4296    0.4727    0.4480     96794\n",
      "\n",
      "Round 21 Loss: 0.36788538 Examples: 13120\n",
      "Round 22 Loss: 0.36053988 Examples: 13120\n",
      "Round 23 Loss: 0.3674824 Examples: 13120\n",
      "Round 24 Loss: 0.3616484 Examples: 13120\n",
      "Round 25 Loss: 0.35815966 Examples: 13120\n",
      "Round 26 Loss: 0.36005187 Examples: 13120\n",
      "Round 27 Loss: 0.35531053 Examples: 13120\n",
      "Round 28 Loss: 0.35720012 Examples: 13120\n",
      "Round 29 Loss: 0.35408965 Examples: 13120\n",
      "Round 30 Loss: 0.3500675 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.2633    0.3410    0.2972      4064\n",
      "         BUI     0.1280    0.1686    0.1455      5007\n",
      "         EVE     0.1871    0.2115    0.1986      4104\n",
      "         LOC     0.5636    0.6281    0.5941     27227\n",
      "        MISC     0.3224    0.2706    0.2942      9558\n",
      "         ORG     0.3075    0.3851    0.3420     19077\n",
      "         PER     0.6723    0.8294    0.7426     21527\n",
      "         PRO     0.3100    0.3210    0.3154      6230\n",
      "\n",
      "   micro avg     0.4473    0.5164    0.4794     96794\n",
      "   macro avg     0.3443    0.3944    0.3662     96794\n",
      "weighted avg     0.4461    0.5164    0.4775     96794\n",
      "\n",
      "Round 31 Loss: 0.34850007 Examples: 13120\n",
      "Round 32 Loss: 0.3474487 Examples: 13120\n",
      "Round 33 Loss: 0.34960148 Examples: 13120\n",
      "Round 34 Loss: 0.35346308 Examples: 13120\n",
      "Round 35 Loss: 0.3469721 Examples: 13120\n",
      "Round 36 Loss: 0.35189518 Examples: 13120\n",
      "Round 37 Loss: 0.34947553 Examples: 13120\n",
      "Round 38 Loss: 0.3471244 Examples: 13120\n",
      "Round 39 Loss: 0.34545454 Examples: 13120\n",
      "Round 40 Loss: 0.34024513 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.2833    0.3492    0.3128      4064\n",
      "         BUI     0.1319    0.1508    0.1407      5007\n",
      "         EVE     0.1923    0.1988    0.1955      4104\n",
      "         LOC     0.5642    0.6612    0.6089     27227\n",
      "        MISC     0.3240    0.2824    0.3018      9558\n",
      "         ORG     0.3162    0.3941    0.3509     19077\n",
      "         PER     0.6860    0.8404    0.7554     21527\n",
      "         PRO     0.3279    0.3087    0.3180      6230\n",
      "\n",
      "   micro avg     0.4606    0.5292    0.4925     96794\n",
      "   macro avg     0.3532    0.3982    0.3730     96794\n",
      "weighted avg     0.4536    0.5292    0.4874     96794\n",
      "\n",
      "Round 41 Loss: 0.34650016 Examples: 13120\n",
      "Round 42 Loss: 0.3430593 Examples: 13120\n",
      "Round 43 Loss: 0.34552184 Examples: 13120\n",
      "Round 44 Loss: 0.34035203 Examples: 13120\n",
      "Round 45 Loss: 0.34901068 Examples: 13120\n",
      "Round 46 Loss: 0.34688136 Examples: 13120\n",
      "Round 47 Loss: 0.34055042 Examples: 13120\n",
      "Round 48 Loss: 0.33934334 Examples: 13120\n",
      "Round 49 Loss: 0.33648244 Examples: 13120\n",
      "Round 50 Loss: 0.34528983 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.2951    0.3607    0.3247      4064\n",
      "         BUI     0.1359    0.1576    0.1459      5007\n",
      "         EVE     0.2034    0.2096    0.2064      4104\n",
      "         LOC     0.5634    0.6787    0.6157     27227\n",
      "        MISC     0.3309    0.2811    0.3040      9558\n",
      "         ORG     0.3199    0.4092    0.3591     19077\n",
      "         PER     0.6924    0.8441    0.7608     21527\n",
      "         PRO     0.3401    0.3048    0.3215      6230\n",
      "\n",
      "   micro avg     0.4651    0.5388    0.4992     96794\n",
      "   macro avg     0.3601    0.4057    0.3798     96794\n",
      "weighted avg     0.4581    0.5388    0.4938     96794\n",
      "\n",
      "Round 51 Loss: 0.34059334 Examples: 13120\n",
      "Round 52 Loss: 0.34234425 Examples: 13120\n",
      "Round 53 Loss: 0.3380218 Examples: 13120\n",
      "Round 54 Loss: 0.3411395 Examples: 13120\n",
      "Round 55 Loss: 0.34724498 Examples: 13120\n",
      "Round 56 Loss: 0.34785417 Examples: 13120\n",
      "Round 57 Loss: 0.34209266 Examples: 13120\n",
      "Round 58 Loss: 0.34341398 Examples: 13120\n",
      "Round 59 Loss: 0.34013596 Examples: 13120\n",
      "Round 60 Loss: 0.33894575 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.3037    0.3750    0.3356      4064\n",
      "         BUI     0.1461    0.1786    0.1607      5007\n",
      "         EVE     0.2169    0.2410    0.2283      4104\n",
      "         LOC     0.5712    0.6804    0.6210     27227\n",
      "        MISC     0.3349    0.2776    0.3036      9558\n",
      "         ORG     0.3242    0.4043    0.3599     19077\n",
      "         PER     0.6944    0.8477    0.7634     21527\n",
      "         PRO     0.3319    0.3319    0.3319      6230\n",
      "\n",
      "   micro avg     0.4683    0.5436    0.5031     96794\n",
      "   macro avg     0.3654    0.4171    0.3881     96794\n",
      "weighted avg     0.4629    0.5436    0.4988     96794\n",
      "\n",
      "Round 61 Loss: 0.34158155 Examples: 13120\n",
      "Round 62 Loss: 0.3378546 Examples: 13120\n",
      "Round 63 Loss: 0.33957165 Examples: 13120\n",
      "Round 64 Loss: 0.34051874 Examples: 13120\n",
      "Round 65 Loss: 0.34319833 Examples: 13120\n",
      "Round 66 Loss: 0.3435594 Examples: 13120\n",
      "Round 67 Loss: 0.3415343 Examples: 13120\n",
      "Round 68 Loss: 0.34093276 Examples: 13120\n",
      "Round 69 Loss: 0.33785746 Examples: 13120\n",
      "Round 70 Loss: 0.33897015 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.3073    0.3723    0.3367      4064\n",
      "         BUI     0.1474    0.1750    0.1600      5007\n",
      "         EVE     0.2134    0.2329    0.2228      4104\n",
      "         LOC     0.5742    0.6776    0.6216     27227\n",
      "        MISC     0.3339    0.3073    0.3200      9558\n",
      "         ORG     0.3263    0.4094    0.3631     19077\n",
      "         PER     0.6984    0.8478    0.7659     21527\n",
      "         PRO     0.3431    0.3178    0.3300      6230\n",
      "\n",
      "   micro avg     0.4707    0.5452    0.5052     96794\n",
      "   macro avg     0.3680    0.4175    0.3900     96794\n",
      "weighted avg     0.4658    0.5452    0.5015     96794\n",
      "\n",
      "Round 71 Loss: 0.33784577 Examples: 13120\n",
      "Round 72 Loss: 0.34622487 Examples: 13120\n",
      "Round 73 Loss: 0.33862376 Examples: 13120\n",
      "Round 74 Loss: 0.34057906 Examples: 13120\n",
      "Round 75 Loss: 0.3393586 Examples: 13120\n",
      "Round 76 Loss: 0.3416616 Examples: 13120\n",
      "Round 77 Loss: 0.34186503 Examples: 13120\n",
      "Round 78 Loss: 0.33876887 Examples: 13120\n",
      "Round 79 Loss: 0.33635235 Examples: 13120\n",
      "Round 80 Loss: 0.33980802 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.3081    0.3787    0.3398      4064\n",
      "         BUI     0.1516    0.1921    0.1695      5007\n",
      "         EVE     0.2186    0.2356    0.2268      4104\n",
      "         LOC     0.5727    0.6818    0.6225     27227\n",
      "        MISC     0.3349    0.2891    0.3103      9558\n",
      "         ORG     0.3251    0.4144    0.3644     19077\n",
      "         PER     0.7043    0.8465    0.7689     21527\n",
      "         PRO     0.3338    0.3372    0.3355      6230\n",
      "\n",
      "   micro avg     0.4696    0.5478    0.5057     96794\n",
      "   macro avg     0.3686    0.4219    0.3922     96794\n",
      "weighted avg     0.4664    0.5478    0.5028     96794\n",
      "\n",
      "Round 81 Loss: 0.3397263 Examples: 13120\n",
      "Round 82 Loss: 0.34534517 Examples: 13120\n",
      "Round 83 Loss: 0.33684543 Examples: 13120\n",
      "Round 84 Loss: 0.341076 Examples: 13120\n",
      "Round 85 Loss: 0.33957028 Examples: 13120\n",
      "Round 86 Loss: 0.33343625 Examples: 13120\n",
      "Round 87 Loss: 0.33624402 Examples: 13120\n",
      "Round 88 Loss: 0.33705607 Examples: 13120\n",
      "Round 89 Loss: 0.33849996 Examples: 13120\n",
      "Round 90 Loss: 0.3398705 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.3057    0.3949    0.3446      4064\n",
      "         BUI     0.1501    0.1845    0.1655      5007\n",
      "         EVE     0.2174    0.2400    0.2281      4104\n",
      "         LOC     0.5708    0.6809    0.6210     27227\n",
      "        MISC     0.3401    0.2744    0.3038      9558\n",
      "         ORG     0.3266    0.4019    0.3604     19077\n",
      "         PER     0.7024    0.8474    0.7681     21527\n",
      "         PRO     0.3429    0.3141    0.3279      6230\n",
      "\n",
      "   micro avg     0.4721    0.5428    0.5050     96794\n",
      "   macro avg     0.3695    0.4173    0.3899     96794\n",
      "weighted avg     0.4666    0.5428    0.5003     96794\n",
      "\n",
      "Round 91 Loss: 0.3443713 Examples: 13120\n",
      "Round 92 Loss: 0.33596787 Examples: 13120\n",
      "Round 93 Loss: 0.34148094 Examples: 13120\n",
      "Round 94 Loss: 0.34005934 Examples: 13120\n",
      "Round 95 Loss: 0.33974773 Examples: 13120\n",
      "Round 96 Loss: 0.3376139 Examples: 13120\n",
      "Round 97 Loss: 0.3428282 Examples: 13120\n",
      "Round 98 Loss: 0.33542946 Examples: 13120\n",
      "Round 99 Loss: 0.34074283 Examples: 13120\n",
      "Round 100 Loss: 0.34028232 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.3070    0.3706    0.3358      4064\n",
      "         BUI     0.1513    0.1825    0.1655      5007\n",
      "         EVE     0.2176    0.2446    0.2303      4104\n",
      "         LOC     0.5755    0.6804    0.6236     27227\n",
      "        MISC     0.3334    0.3084    0.3205      9558\n",
      "         ORG     0.3280    0.4116    0.3651     19077\n",
      "         PER     0.6941    0.8506    0.7644     21527\n",
      "         PRO     0.3376    0.3193    0.3282      6230\n",
      "\n",
      "   micro avg     0.4703    0.5481    0.5062     96794\n",
      "   macro avg     0.3681    0.4210    0.3917     96794\n",
      "weighted avg     0.4655    0.5481    0.5026     96794\n",
      "\n",
      "Round 101 Loss: 0.34050927 Examples: 13120\n",
      "Round 102 Loss: 0.33295712 Examples: 13120\n",
      "Round 103 Loss: 0.3411249 Examples: 13120\n",
      "Round 104 Loss: 0.338608 Examples: 13120\n",
      "Round 105 Loss: 0.33667082 Examples: 13120\n",
      "Round 106 Loss: 0.3407938 Examples: 13120\n",
      "Round 107 Loss: 0.33918488 Examples: 13120\n",
      "Round 108 Loss: 0.3338463 Examples: 13120\n",
      "Round 109 Loss: 0.33955306 Examples: 13120\n",
      "Round 110 Loss: 0.3377458 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.3105    0.4050    0.3515      4064\n",
      "         BUI     0.1529    0.1969    0.1722      5007\n",
      "         EVE     0.2197    0.2349    0.2270      4104\n",
      "         LOC     0.5750    0.6815    0.6237     27227\n",
      "        MISC     0.3420    0.2756    0.3052      9558\n",
      "         ORG     0.3245    0.4194    0.3659     19077\n",
      "         PER     0.7043    0.8470    0.7691     21527\n",
      "         PRO     0.3403    0.3196    0.3296      6230\n",
      "\n",
      "   micro avg     0.4712    0.5476    0.5066     96794\n",
      "   macro avg     0.3712    0.4225    0.3930     96794\n",
      "weighted avg     0.4683    0.5476    0.5033     96794\n",
      "\n",
      "Round 111 Loss: 0.3402899 Examples: 13120\n",
      "Round 112 Loss: 0.33600995 Examples: 13120\n",
      "Round 113 Loss: 0.33373272 Examples: 13120\n",
      "Round 114 Loss: 0.34138086 Examples: 13120\n",
      "Round 115 Loss: 0.34187374 Examples: 13120\n",
      "Round 116 Loss: 0.3365981 Examples: 13120\n",
      "Round 117 Loss: 0.34345952 Examples: 13120\n",
      "Round 118 Loss: 0.33732983 Examples: 13120\n",
      "Round 119 Loss: 0.33970878 Examples: 13120\n",
      "Round 120 Loss: 0.33978814 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.3086    0.3937    0.3460      4064\n",
      "         BUI     0.1479    0.1718    0.1590      5007\n",
      "         EVE     0.2230    0.2446    0.2333      4104\n",
      "         LOC     0.5785    0.6722    0.6218     27227\n",
      "        MISC     0.3361    0.2806    0.3059      9558\n",
      "         ORG     0.3284    0.4161    0.3671     19077\n",
      "         PER     0.7003    0.8484    0.7673     21527\n",
      "         PRO     0.3411    0.3233    0.3319      6230\n",
      "\n",
      "   micro avg     0.4733    0.5441    0.5062     96794\n",
      "   macro avg     0.3705    0.4188    0.3915     96794\n",
      "weighted avg     0.4684    0.5441    0.5021     96794\n",
      "\n",
      "Round 121 Loss: 0.33622956 Examples: 13120\n",
      "Round 122 Loss: 0.33893344 Examples: 13120\n",
      "Round 123 Loss: 0.33655146 Examples: 13120\n",
      "Round 124 Loss: 0.34579232 Examples: 13120\n",
      "Round 125 Loss: 0.3368505 Examples: 13120\n",
      "Round 126 Loss: 0.34261116 Examples: 13120\n",
      "Round 127 Loss: 0.33570656 Examples: 13120\n",
      "Round 128 Loss: 0.33385435 Examples: 13120\n",
      "Round 129 Loss: 0.3364752 Examples: 13120\n",
      "Round 130 Loss: 0.33434102 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.3125    0.3984    0.3502      4064\n",
      "         BUI     0.1504    0.1879    0.1671      5007\n",
      "         EVE     0.2223    0.2546    0.2374      4104\n",
      "         LOC     0.5717    0.6878    0.6244     27227\n",
      "        MISC     0.3362    0.2772    0.3038      9558\n",
      "         ORG     0.3281    0.4070    0.3633     19077\n",
      "         PER     0.7007    0.8492    0.7678     21527\n",
      "         PRO     0.3358    0.3257    0.3307      6230\n",
      "\n",
      "   micro avg     0.4713    0.5481    0.5068     96794\n",
      "   macro avg     0.3697    0.4235    0.3931     96794\n",
      "weighted avg     0.4664    0.5481    0.5027     96794\n",
      "\n",
      "Round 131 Loss: 0.34424332 Examples: 13120\n",
      "Round 132 Loss: 0.33755416 Examples: 13120\n",
      "Round 133 Loss: 0.3384986 Examples: 13120\n",
      "Round 134 Loss: 0.33645043 Examples: 13120\n",
      "Round 135 Loss: 0.33912975 Examples: 13120\n",
      "Round 136 Loss: 0.33894193 Examples: 13120\n",
      "Round 137 Loss: 0.33578122 Examples: 13120\n",
      "Round 138 Loss: 0.33932313 Examples: 13120\n",
      "Round 139 Loss: 0.3378837 Examples: 13120\n",
      "Round 140 Loss: 0.33348244 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ART     0.3113    0.3964    0.3487      4064\n",
      "         BUI     0.1485    0.1734    0.1600      5007\n",
      "         EVE     0.2164    0.2276    0.2219      4104\n",
      "         LOC     0.5730    0.6844    0.6237     27227\n",
      "        MISC     0.3368    0.2813    0.3066      9558\n",
      "         ORG     0.3253    0.4255    0.3687     19077\n",
      "         PER     0.7086    0.8449    0.7707     21527\n",
      "         PRO     0.3354    0.3189    0.3269      6230\n",
      "\n",
      "   micro avg     0.4718    0.5478    0.5070     96794\n",
      "   macro avg     0.3694    0.4190    0.3909     96794\n",
      "weighted avg     0.4676    0.5478    0.5032     96794\n",
      "\n",
      "Round 141 Loss: 0.3356126 Examples: 13120\n",
      "Round 142 Loss: 0.33827817 Examples: 13120\n",
      "Round 143 Loss: 0.33591455 Examples: 13120\n",
      "Round 144 Loss: 0.33611265 Examples: 13120\n",
      "Round 145 Loss: 0.3378339 Examples: 13120\n",
      "Round 146 Loss: 0.33624423 Examples: 13120\n",
      "Round 147 Loss: 0.3365317 Examples: 13120\n",
      "Round 148 Loss: 0.33892807 Examples: 13120\n",
      "Round 149 Loss: 0.3405669 Examples: 13120\n",
      "Round 150 Loss: 0.33487192 Examples: 13120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6807889b844118b4cd62e6022d33ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/589 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_clients, num_train_clients = 100, 10\n",
    "assert num_clients >= num_train_clients\n",
    "\n",
    "dataset_list = split_to_tf_datasets(train_features, num_clients, batch_size=BATCH_SIZE)\n",
    "trainer = tff.learning.build_federated_averaging_process(\n",
    "    model_fn=lambda: model_fn(MODEL, processor.label_len(), SEQ_LEN, dataset_list[0].element_spec),\n",
    "    client_optimizer_fn=lambda: tf.keras.optimizers.Adam(5e-3),\n",
    "    server_optimizer_fn=lambda: tf.keras.optimizers.Adam(5e-3),\n",
    "    use_experimental_simulation_loop=True\n",
    ")\n",
    "\n",
    "state = trainer.initialize()\n",
    "if PRETRAINED:\n",
    "    pret_model = build_BertNer(MODEL, processor.label_len(), SEQ_LEN)\n",
    "    for layer in pret_model.layers:\n",
    "        if (isinstance(layer, bert_modeling.BertModel)):\n",
    "            layer.trainable = False\n",
    "    state = state_from_checkpoint(state, pret_model, MODEL)\n",
    "\n",
    "            \n",
    "res_list=[]\n",
    "examples = 0\n",
    "for rnd_ind in range(1, 501):\n",
    "    train_data = list(np.random.choice(dataset_list, num_train_clients, replace=False))\n",
    "    state, metrics = trainer.next(state, train_data)\n",
    "    print(\"Round\", rnd_ind, \"Loss:\", metrics['train']['loss'], \"Examples:\", metrics['stat']['num_examples'])\n",
    "    examples = metrics['stat']['num_examples']\n",
    "    # tf.nest.assert_same_structure(state_model, eval_model, check_types=False, expand_composites=True)\n",
    "    \n",
    "    # Ne treba svaku rundu gledati tocnost, moze svakih 10 (jedna epoha kumulativno)\n",
    "    if rnd_ind % num_train_clients == 0:\n",
    "        state_model = state_to_pretrained_model(build_BertNer(MODEL, processor.label_len(), SEQ_LEN), state)\n",
    "        # state_model = state_to_model(state, build_BertNer(MODEL, processor.label_len(), SEQ_LEN))\n",
    "        res = eval_model(state_model, eval_data_batched, do_print=True)\n",
    "        res['Round'] = rnd_ind\n",
    "        res['Examples'] = examples\n",
    "        res_list.append(res)\n",
    "\n",
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        if isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return super(NpEncoder, self).default(obj)\n",
    "\n",
    "with open(\"log/results-\"+modelSize+\"-\"+pretr+\"-\"+datas+\"-1.json\", \"w\") as outfile:\n",
    "    json.dump({'results': res_list, 'model': MODEL, 'seq_len': SEQ_LEN, \n",
    "               'pretrained': PRETRAINED, 'batch_size': BATCH_SIZE}, outfile, indent=None, cls=NpEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ab5fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fl_borina]",
   "language": "python",
   "name": "conda-env-fl_borina-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
